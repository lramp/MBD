{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lramp\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/Users/lramp/Downloads/train_cris.csv\")\n",
    "test = pd.read_csv(\"/Users/lramp/Downloads/test_cris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (76020, 371)  Test shape:  (929615, 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape: \",train.shape,\" Test shape: \",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    73012\n",
       "1     3008\n",
       "Name: ID, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0396 of the observations have good customer satisfaction\n"
     ]
    }
   ],
   "source": [
    "train_results = train.groupby('TARGET')['ID'].count()\n",
    "display(train_results)\n",
    "satisfied = len(train[train['TARGET'] == 1]) / len(train)\n",
    "print(\"%1.4f of the observations have good customer satisfaction\" % satisfied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['TARGET']\n",
    "train = train.drop(['TARGET'], axis=1)\n",
    "\n",
    "# save and remove ID\n",
    "train_id = train['ID']\n",
    "train = train.drop('ID', axis = 1)\n",
    "#test_id = test['ID']\n",
    "#test = test.drop('ID', axis = 1)\n",
    "\n",
    "# create an array with both df's for simplicity when cleaning\n",
    "both_df = [train, test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [0, 1]\n",
      "Index: []\n",
      "There are 0 columns with missing values\n",
      "None\n",
      "------------------------\n",
      "                     0        1\n",
      "conyuemp        929511   object\n",
      "ult_fec_cli_1t  927932   object\n",
      "cod_prov          3996  float64\n",
      "nomprov           3996   object\n",
      "segmento          2248   object\n",
      "canal_entrada     2081   object\n",
      "indrel_1mes         23  float64\n",
      "tiprel_1mes         23   object\n",
      "sexo                 5   object\n",
      "There are 9 columns with missing values\n",
      "None\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# create a function to check nulls\n",
    "def check_nulls(df):\n",
    "    nulls = np.sum(df.isnull())\n",
    "    nullcols = nulls.loc[(nulls != 0)]\n",
    "    d_types = df.dtypes.loc[(nulls != 0)]\n",
    "    info = pd.concat([nullcols, d_types], axis=1).sort_values(by=0, ascending=False)\n",
    "    print(info)\n",
    "    print(\"There are\", len(nullcols), \"columns with missing values\")\n",
    "    \n",
    "# use the function    \n",
    "for i in both_df:\n",
    "    print(check_nulls(i))\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no nulls in both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  34  Test:  2\n"
     ]
    }
   ],
   "source": [
    "no_use_train = []\n",
    "for c in train:\n",
    "    if train[c].nunique() == 1:\n",
    "        no_use_train.append(c)\n",
    "\n",
    "no_use_test = []\n",
    "for c in test:\n",
    "    if test[c].nunique() == 1:\n",
    "        no_use_test.append(c)\n",
    "        \n",
    "print(\"Train: \", len(no_use_train), \" Test: \", len(no_use_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test has more so we will drop the extra columns\n",
    "\n",
    "test = test.drop(no_use_test, axis=1)\n",
    "train = train.drop(no_use_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 34 columns in the train df that have only 1 value, while there are 45 columns in the test df that have only 1 value. We will get rid of the higher amount and redo the check to see if there were some in train that were not in test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.kaggle.com/tilii7/bayesian-optimization-of-xgboost-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comment out any parameter you don't want to test\n",
    "def XGB_CV(\n",
    "          max_depth,\n",
    "          gamma,\n",
    "          min_child_weight,\n",
    "          max_delta_step,\n",
    "          subsample,\n",
    "          colsample_bytree\n",
    "         ):\n",
    "\n",
    "    global AUCbest\n",
    "    global ITERbest\n",
    "\n",
    "#\n",
    "# Define all XGboost parameters\n",
    "#\n",
    "\n",
    "    paramt = {\n",
    "              'booster' : 'gbtree',\n",
    "              'max_depth' : int(max_depth),\n",
    "              'gamma' : gamma,\n",
    "              'eta' : 0.05,\n",
    "              'objective' : 'binary:logistic',\n",
    "              'nthread' : 4,\n",
    "              'silent' : True,\n",
    "              'eval_metric': 'auc',\n",
    "              'subsample' : max(min(subsample, 1), 0),\n",
    "              'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "              'min_child_weight' : min_child_weight,\n",
    "              'max_delta_step' : int(max_delta_step),\n",
    "              'seed' : 65\n",
    "              }\n",
    "\n",
    "    folds = 5\n",
    "    cv_score = 0\n",
    "\n",
    "    print(\"\\n Search parameters (%d-fold validation):\\n %s\" % (folds, paramt), file=log_file )\n",
    "    log_file.flush()\n",
    "\n",
    "    xgbc = xgb.cv(\n",
    "                    paramt,\n",
    "                    dtrain,\n",
    "                    num_boost_round = 20000,\n",
    "                    stratified = True,\n",
    "                    nfold = folds,\n",
    "#                    verbose_eval = 10,\n",
    "                    early_stopping_rounds = 100,\n",
    "                    metrics = 'auc',\n",
    "                    show_stdv = True\n",
    "               )\n",
    "\n",
    "    val_score = xgbc['test-auc-mean'].iloc[-1]\n",
    "    train_score = xgbc['train-auc-mean'].iloc[-1]\n",
    "    print(' Stopped after %d iterations with train-auc = %f val-auc = %f ( diff = %f ) train-gini = %f val-gini = %f' % ( len(xgbc), train_score, val_score, (train_score - val_score), (train_score*2-1),\n",
    "(val_score*2-1)) )\n",
    "    if ( val_score > AUCbest ):\n",
    "        AUCbest = val_score\n",
    "        ITERbest = len(xgbc)\n",
    "\n",
    "    return (val_score*2) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the log file. If you repeat this run, new output will be added to it\n",
    "log_file = open('Santander-AUC-5fold-XGB-run-01-v1-full.log', 'a')\n",
    "AUCbest = -1.\n",
    "ITERbest = 0\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, StratifiedShuffleSplit\n",
    "import gc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train, label = target)\n",
    "\n",
    "sss = StratifiedShuffleSplit(target, random_state=1001, test_size=0.75)\n",
    "for train_index, test_index in sss:\n",
    "    break\n",
    "#X_train, y_train = train[train_index], target[train_index]\n",
    "#del train, target\n",
    "gc.collect()\n",
    "dtrain = xgb.DMatrix(X_train, label = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB_BO = BayesianOptimization(XGB_CV, {\n",
    "                                     'max_depth': (2, 12),\n",
    "                                     'gamma': (0.001, 10.0),\n",
    "                                     'min_child_weight': (0, 20),\n",
    "                                     'max_delta_step': (0, 10),\n",
    "                                     'subsample': (0.4, 1.0),\n",
    "                                     'colsample_bytree' :(0.4, 1.0)\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XGB_BO.explore({\n",
    "              'max_depth':            [3, 8, 3, 8, 8, 3, 8, 3],\n",
    "              'gamma':                [0.5, 8, 0.2, 9, 0.5, 8, 0.2, 9],\n",
    "              'min_child_weight':     [0.2, 0.2, 0.2, 0.2, 12, 12, 12, 12],\n",
    "              'max_delta_step':       [1, 2, 2, 1, 2, 1, 1, 2],\n",
    "              'subsample':            [0.6, 0.8, 0.6, 0.8, 0.6, 0.8, 0.6, 0.8],\n",
    "              'colsample_bytree':     [0.6, 0.8, 0.6, 0.8, 0.6, 0.8, 0.6, 0.8],\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n",
      " Stopped after 246 iterations with train-auc = 0.861983 val-auc = 0.838475 ( diff = 0.023508 ) train-gini = 0.723966 val-gini = 0.676949\n",
      "    1 | 03m18s | \u001b[35m   0.67695\u001b[0m | \u001b[32m            0.6000\u001b[0m | \u001b[32m   0.5000\u001b[0m | \u001b[32m          1.0000\u001b[0m | \u001b[32m     3.0000\u001b[0m | \u001b[32m            0.2000\u001b[0m | \u001b[32m     0.6000\u001b[0m | \n",
      " Stopped after 208 iterations with train-auc = 0.882920 val-auc = 0.838720 ( diff = 0.044199 ) train-gini = 0.765839 val-gini = 0.677441\n",
      "    2 | 10m22s | \u001b[35m   0.67744\u001b[0m | \u001b[32m            0.8000\u001b[0m | \u001b[32m   8.0000\u001b[0m | \u001b[32m          2.0000\u001b[0m | \u001b[32m     8.0000\u001b[0m | \u001b[32m            0.2000\u001b[0m | \u001b[32m     0.8000\u001b[0m | \n",
      " Stopped after 242 iterations with train-auc = 0.863952 val-auc = 0.838537 ( diff = 0.025415 ) train-gini = 0.727904 val-gini = 0.677073\n",
      "    3 | 03m56s |    0.67707 |             0.6000 |    0.2000 |           2.0000 |      3.0000 |             0.2000 |      0.6000 | \n",
      " Stopped after 202 iterations with train-auc = 0.869022 val-auc = 0.838799 ( diff = 0.030223 ) train-gini = 0.738045 val-gini = 0.677598\n",
      "    4 | 10m34s | \u001b[35m   0.67760\u001b[0m | \u001b[32m            0.8000\u001b[0m | \u001b[32m   9.0000\u001b[0m | \u001b[32m          1.0000\u001b[0m | \u001b[32m     8.0000\u001b[0m | \u001b[32m            0.2000\u001b[0m | \u001b[32m     0.8000\u001b[0m | \n",
      " Stopped after 131 iterations with train-auc = 0.879551 val-auc = 0.839084 ( diff = 0.040467 ) train-gini = 0.759101 val-gini = 0.678167\n",
      "    5 | 07m09s | \u001b[35m   0.67817\u001b[0m | \u001b[32m            0.6000\u001b[0m | \u001b[32m   0.5000\u001b[0m | \u001b[32m          2.0000\u001b[0m | \u001b[32m     8.0000\u001b[0m | \u001b[32m           12.0000\u001b[0m | \u001b[32m     0.6000\u001b[0m | \n",
      " Stopped after 879 iterations with train-auc = 0.858756 val-auc = 0.838512 ( diff = 0.020244 ) train-gini = 0.717512 val-gini = 0.677024\n",
      "    6 | 13m38s |    0.67702 |             0.8000 |    8.0000 |           1.0000 |      3.0000 |            12.0000 |      0.8000 | \n",
      " Stopped after 150 iterations with train-auc = 0.880269 val-auc = 0.838733 ( diff = 0.041536 ) train-gini = 0.760538 val-gini = 0.677465\n",
      "    7 | 06m50s |    0.67747 |             0.6000 |    0.2000 |           1.0000 |      8.0000 |            12.0000 |      0.6000 | \n",
      " Stopped after 858 iterations with train-auc = 0.856100 val-auc = 0.837965 ( diff = 0.018135 ) train-gini = 0.712200 val-gini = 0.675930\n",
      "    8 | 14m11s |    0.67593 |             0.8000 |    9.0000 |           2.0000 |      3.0000 |            12.0000 |      0.8000 | \n",
      " Stopped after 125 iterations with train-auc = 0.893174 val-auc = 0.839220 ( diff = 0.053955 ) train-gini = 0.786349 val-gini = 0.678439\n",
      "    9 | 06m31s | \u001b[35m   0.67844\u001b[0m | \u001b[32m            0.7157\u001b[0m | \u001b[32m   3.5945\u001b[0m | \u001b[32m          8.8780\u001b[0m | \u001b[32m     7.5115\u001b[0m | \u001b[32m            1.5871\u001b[0m | \u001b[32m     0.8605\u001b[0m | \n",
      " Stopped after 608 iterations with train-auc = 0.854705 val-auc = 0.837266 ( diff = 0.017439 ) train-gini = 0.709410 val-gini = 0.674531\n",
      "   10 | 05m55s |    0.67453 |             0.5684 |    4.8907 |           9.4165 |      2.9422 |            15.0577 |      0.7726 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_delta_step |   max_depth |   min_child_weight |   subsample | \n",
      " Stopped after 96 iterations with train-auc = 0.898435 val-auc = 0.836795 ( diff = 0.061640 ) train-gini = 0.796869 val-gini = 0.673589\n",
      "   11 | 10m19s |    0.67359 |             0.9893 |    0.1057 |           9.7337 |     11.3837 |             9.3898 |      0.8029 | \n",
      " Stopped after 370 iterations with train-auc = 0.857108 val-auc = 0.837563 ( diff = 0.019545 ) train-gini = 0.714217 val-gini = 0.675127\n",
      "   12 | 03m12s |    0.67513 |             0.4004 |    5.8483 |           0.5113 |      3.5719 |             5.9422 |      0.4006 | \n",
      " Stopped after 375 iterations with train-auc = 0.865314 val-auc = 0.839107 ( diff = 0.026207 ) train-gini = 0.730628 val-gini = 0.678214\n",
      "   13 | 12m03s |    0.67821 |             0.6207 |    8.4473 |           0.4076 |     11.5672 |            19.8724 |      0.9890 | \n",
      " Stopped after 252 iterations with train-auc = 0.866022 val-auc = 0.839309 ( diff = 0.026713 ) train-gini = 0.732044 val-gini = 0.678618\n",
      "   14 | 02m38s | \u001b[35m   0.67862\u001b[0m | \u001b[32m            0.4063\u001b[0m | \u001b[32m   1.2174\u001b[0m | \u001b[32m          3.3488\u001b[0m | \u001b[32m     4.8212\u001b[0m | \u001b[32m           17.4818\u001b[0m | \u001b[32m     0.9892\u001b[0m | \n",
      " Stopped after 141 iterations with train-auc = 0.874569 val-auc = 0.838354 ( diff = 0.036215 ) train-gini = 0.749139 val-gini = 0.676708\n",
      "   15 | 05m20s |    0.67671 |             0.8424 |    3.7475 |           4.1736 |      7.0501 |            11.3899 |      0.9932 | \n"
     ]
    }
   ],
   "source": [
    "print('-'*130)\n",
    "print('-'*130, file=log_file)\n",
    "log_file.flush()\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    XGB_BO.maximize(init_points=2, n_iter=5, acq='ei', xi=0.0)\n",
    "\n",
    "# XGB_BO.maximize(init_points=10, n_iter=50, acq='ei', xi=0.0)\n",
    "# XGB_BO.maximize(init_points=10, n_iter=50, acq='ei', xi=0.01)\n",
    "# XGB_BO.maximize(init_points=10, n_iter=50, acq='ucb', kappa=10)\n",
    "# XGB_BO.maximize(init_points=10, n_iter=50, acq='ucb', kappa=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Final Results\n",
      "Maximum XGBOOST value: 0.678618\n",
      "Best XGBOOST parameters:  {'max_depth': 4.821237005728406, 'gamma': 1.2173520371228357, 'min_child_weight': 17.48179322089674, 'max_delta_step': 3.3487895352177874, 'subsample': 0.9891855746808983, 'colsample_bytree': 0.4063322759811285}\n"
     ]
    }
   ],
   "source": [
    "print('-'*130)\n",
    "print('Final Results')\n",
    "print('Maximum XGBOOST value: %f' % XGB_BO.res['max']['max_val'])\n",
    "print('Best XGBOOST parameters: ', XGB_BO.res['max']['max_params'])\n",
    "print('-'*130, file=log_file)\n",
    "print('Final Result:', file=log_file)\n",
    "print('Maximum XGBOOST value: %f' % XGB_BO.res['max']['max_val'], file=log_file)\n",
    "print('Best XGBOOST parameters: ', XGB_BO.res['max']['max_params'], file=log_file)\n",
    "log_file.flush()\n",
    "log_file.close()\n",
    "\n",
    "history_df = pd.DataFrame(XGB_BO.res['all']['params'])\n",
    "history_df2 = pd.DataFrame(XGB_BO.res['all']['values'])\n",
    "history_df = pd.concat((history_df, history_df2), axis=1)\n",
    "history_df.rename(columns = { 0 : 'gini'}, inplace=True)\n",
    "history_df['AUC'] = ( history_df['gini'] + 1 ) / 2\n",
    "history_df.to_csv('Santander-AUC-5fold-XGB-run-01-v1-grid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
